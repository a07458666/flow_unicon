{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1daf44e8-72dd-4938-b34a-110a39a2706b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andysu/workspace/flow/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from syslog import LOG_MAIL\n",
    "from urllib3 import Retry\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# \n",
    "import time\n",
    "import collections.abc\n",
    "from flow_trainer import FlowTrainer\n",
    "from tqdm import tqdm\n",
    "from config import argumentParse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from dataloader_cifar import cifar_dataloader as dataloader\n",
    "from PreResNet_cifar import *\n",
    "\n",
    "wandb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b423d65d-f72f-41dd-8070-68d3d50a43dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to argument parse\n"
     ]
    }
   ],
   "source": [
    "# name = 'siamese_lossNll_UNICON_Tf_1.0_0.7_w_FlowSp_T_0.5_center_0.8_lamba_f_0.1_fixJSD'\n",
    "name = 'twoNet_lossNLL_wo_blur'\n",
    "args = argumentParse(input_args=['--gpuid', '0,1', '--ratio', '0.9', '--config', './config/cifar100.yaml', '--name', name])\n",
    "## GPU Setup \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpuid\n",
    "# torch.cuda.set_device(args.gpuid)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0afde93d-8428-4256-a098-3b3253451dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Download the Datasets\n",
    "if args.dataset== 'cifar10':\n",
    "    torchvision.datasets.CIFAR10(args.data_path,train=True, download=True)\n",
    "    torchvision.datasets.CIFAR10(args.data_path,train=False, download=True)\n",
    "else:\n",
    "    torchvision.datasets.CIFAR100(args.data_path,train=True, download=True)\n",
    "    torchvision.datasets.CIFAR100(args.data_path,train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc7144e-e6c4-4b07-9b4f-0422ac6b0281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folder = args.dataset + '_' + args.noise_mode + '_' + str(args.ratio)\n",
    "folder = args.dataset + '_' + args.noise_mode + '_' + str(args.ratio)  + '_flow_' + args.name\n",
    "model_save_loc = './checkpoint/' + folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90563a0-b216-425d-a0e2-9e5aad06b544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = ResNet18(num_classes=args.num_class, feature_dim=args.cond_size)\n",
    "    model = model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2048af3-3263-4c8d-8a86-4c6f9378d0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Test Accuracy\n",
    "def getFeature(net):\n",
    "    net.eval()\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    # num_samples = 1000\n",
    "    # correct = 0\n",
    "    # total = 0\n",
    "    # loss_x = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            feature, _ = net1(inputs)\n",
    "            # print(\"feature \", feature.size())\n",
    "            features.append(feature)\n",
    "            labels.append(targets)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    print(\"features list\", features.size())\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53774d6b-b92e-43fa-ab88-39a95f297831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Call the dataloader\n",
    "loader = dataloader(args.dataset, r=args.ratio, noise_mode=args.noise_mode,batch_size=args.batch_size,num_workers=args.num_workers,\\\n",
    "            root_dir=model_save_loc, noise_file='%s/clean_%.4f_%s.npz'%(args.data_path,args.ratio, args.noise_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7108197c-5b54-4861-ba86-8b52825bb246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Building net\n",
      "Training T : 1.0\n",
      "Number of trainable parameters of Point CNF: 391457\n",
      "Training T : 1.0\n",
      "Number of trainable parameters of Point CNF: 391457\n"
     ]
    }
   ],
   "source": [
    "print('| Building net')\n",
    "net1 = create_model()\n",
    "net2 = create_model()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# flow model\n",
    "flowTrainer = FlowTrainer(args)\n",
    "flowNet1 = flowTrainer.create_model()\n",
    "flowNet2 = flowTrainer.create_model()\n",
    "\n",
    "optimizer1 = optim.SGD(net1.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.weight_decay)\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=args.lr, momentum=0.9, weight_decay=args.weight_decay) \n",
    "\n",
    "optimizerFlow1 = optim.SGD(flowNet1.parameters(), lr=args.lr_f, momentum=0.9, weight_decay=args.weight_decay)\n",
    "optimizerFlow2 = optim.SGD(flowNet2.parameters(), lr=args.lr_f, momentum=0.9, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler1 = optim.lr_scheduler.CosineAnnealingLR(optimizer1, args.num_epochs, args.lr / 1e2)\n",
    "schedulerFlow1 = optim.lr_scheduler.CosineAnnealingLR(optimizerFlow1, args.num_epochs, args.lr_f / 1e2)\n",
    "scheduler2 = optim.lr_scheduler.CosineAnnealingLR(optimizer2, args.num_epochs, args.lr / 1e2)\n",
    "schedulerFlow2 = optim.lr_scheduler.CosineAnnealingLR(optimizerFlow2, args.num_epochs, args.lr_f / 1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d2edcd-9137-4e2d-95c1-3207038921d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(path, net, optimizer, scheduler):\n",
    "    device = torch.device('cuda', torch.cuda.current_device())\n",
    "    net_pth = torch.load(path, map_location=device)\n",
    "    net.load_state_dict(net_pth['net'])\n",
    "    # optimizer.load_state_dict(net_pth['optimizer'])\n",
    "    # scheduler.load_state_dict(net_pth['scheduler'])\n",
    "\n",
    "    model_epoch = net_pth['epoch']\n",
    "    return model_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63caaeec-6f4b-4f5c-b13e-109a7a946fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load warmup model\n",
    "_ = load_model(os.path.join(model_save_loc, \"Net_warmup_1.pth\"), net1, optimizer1, scheduler1)\n",
    "_ = load_model(os.path.join(model_save_loc, \"Net_warmup_2.pth\"), net2, optimizer2, scheduler2)\n",
    "_ = load_model(os.path.join(model_save_loc, \"FlowNet_warmup_1.pth\"), flowNet1, optimizerFlow1, schedulerFlow1)\n",
    "epoch = load_model(os.path.join(model_save_loc, \"FlowNet_warmup_2.pth\"), flowNet2, optimizerFlow2, schedulerFlow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c57e98-800b-4cde-aa4f-c90e654b461c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## load warmup model\n",
    "# _ = load_model(os.path.join(model_save_loc, \"Net_1.pth\"), net1, optimizer1, scheduler1)\n",
    "# _ = load_model(os.path.join(model_save_loc, \"Net_2.pth\"), net2, optimizer2, scheduler2)\n",
    "# _ = load_model(os.path.join(model_save_loc, \"FlowNet_1.pth\"), flowNet1, optimizerFlow1, schedulerFlow1)\n",
    "# epoch = load_model(os.path.join(model_save_loc, \"FlowNet_2.pth\"), flowNet2, optimizerFlow2, schedulerFlow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df750fda-e49c-4ab4-9569-113b9c435be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpus\n",
    "if len(args.gpuid) > 1:\n",
    "    net1 = nn.DataParallel(net1)\n",
    "    flowNet1 = nn.DataParallel(flowNet1)\n",
    "    net2 = nn.DataParallel(net2)\n",
    "    flowNet2 = nn.DataParallel(flowNet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044ffe04-efed-4d71-b63c-5fd3984bebf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Test====\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:14,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Test Epoch #28\t Accuracy: 12.87%\t Condifence: 0.03%\n",
      "\n",
      "epoch :  28  acc :  12.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = loader.run(0, 'val')\n",
    "acc, confidence = flowTrainer.testByFlow(epoch, net1, flowNet1, net2, flowNet2, test_loader)\n",
    "print(\"epoch : \", epoch, \" acc : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb1a7a24-3363-4f28-a4c7-946a8bfa8be0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features list torch.Size([10000, 512])\n"
     ]
    }
   ],
   "source": [
    "features, labels = getFeature(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59f21c9c-ea70-49e5-a0d7-6552c499631d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_num = 10\n",
    "labels_target = labels[labels <= target_num]\n",
    "features_target = features[labels <= target_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e13364e-d43f-40fc-9fd3-1e91bb065a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne_reduce(data):\n",
    "    tsne = TSNE(n_components=2, random_state=1)\n",
    "    return tsne.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31480235-6bca-439e-b526-63db71ff126d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature2D = tsne_reduce(features_target.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca22c4b3-3b64-4b9f-9c33-d1e45404adb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = np.unique(labels_target.cpu())\n",
    "data_by_label = [feature2D[labels_target.cpu() == label] for label in unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc8de42a-6614-4cc8-9894-c3a07f3c343e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure()\n",
    "\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "for label, color, data in zip(unique_labels, colors, data_by_label):\n",
    "    plt.scatter(data[:, 0], data[:, 1], color=color, label=label, alpha=0.9, edgecolors='w')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f.savefig(f\"{model_save_loc}/{args.dataset}_{args.noise_mode}_{str(args.ratio)}_{epoch}_t-sne.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951d27cc-1e0c-44a1-92ee-26bbeea35b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:37,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_loader = loader.run(0, 'eval_train')   \n",
    "JSDs = flowTrainer.Calculate_JSD(net1, flowNet1, net2, flowNet2, args.num_samples, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c63e8ea-ecc5-4947-9d22-e229c754327b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = torch.mean(JSDs)\n",
    "SR = torch.sum(JSDs<threshold).item()/args.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f22d982-ea1f-4c16-bb0c-12632e6dfb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logJSD(epoch, threshold, labeled_trainloader, unlabeled_trainloader):\n",
    "    labeled_idx = labeled_trainloader.dataset.pred_idx\n",
    "    unlabeled_idx = unlabeled_trainloader.dataset.pred_idx\n",
    "    origin_prob =  labeled_trainloader.dataset.origin_prob\n",
    "    labeled_prob = [origin_prob[i] for i in labeled_idx]\n",
    "    unlabeled_prob = [origin_prob[i] for i in unlabeled_idx]\n",
    "    sample_ratio = torch.sum(origin_prob<threshold).item()/args.num_samples\n",
    "\n",
    "    num_cleanset, num_noiseset = len(labeled_trainloader.dataset), len(unlabeled_trainloader.dataset)\n",
    "    num_wholeset = num_cleanset + num_noiseset\n",
    "\n",
    "    cleanset_o_label, cleanset_n_label = labeled_trainloader.dataset.origin_label, labeled_trainloader.dataset.noise_label\n",
    "    noiseset_o_label, noiseset_n_label = unlabeled_trainloader.dataset.origin_label, unlabeled_trainloader.dataset.noise_label\n",
    "\n",
    "    cleanset_noise_mask = (cleanset_o_label != cleanset_n_label).astype(float)\n",
    "    noiseset_noise_mask = (noiseset_o_label != noiseset_n_label).astype(float)\n",
    "    \n",
    "    num_cleanset_noise = cleanset_noise_mask.sum()\n",
    "    num_noiseset_noise = noiseset_noise_mask.sum()\n",
    "    num_noise = num_cleanset_noise + num_noiseset_noise\n",
    "\n",
    "    num_cleanset_clean = num_cleanset - num_cleanset_noise\n",
    "    num_noiseset_clean = num_noiseset - num_noiseset_noise\n",
    "    num_clean = num_wholeset - num_noise\n",
    "\n",
    "    eps = 1e-20\n",
    "    clean_recall = num_cleanset_clean / (num_clean + eps)\n",
    "    clean_precision = num_cleanset_clean / (num_cleanset + eps)\n",
    "    clean_f1 = (2 * clean_recall * clean_precision) / (clean_recall + clean_precision + eps)\n",
    "\n",
    "    noise_recall = num_noiseset_noise / (num_noise + eps)\n",
    "    noise_precision = num_noiseset_noise / (num_noiseset + eps)\n",
    "    noise_f1 = (2 * noise_recall * noise_precision) / (noise_recall + noise_precision + eps)\n",
    "\n",
    "    # draw JSD dis\n",
    "    clean_prob = []\n",
    "    noise_prob = []\n",
    "    clean_density = []\n",
    "    noise_density = []\n",
    "    for idx_noise_zip in [zip(labeled_idx, cleanset_noise_mask), zip(unlabeled_idx, noiseset_noise_mask)]:\n",
    "        for idx, is_noise in idx_noise_zip:\n",
    "            p = origin_prob[idx]\n",
    "            if is_noise == 1.0:\n",
    "                noise_prob.append(float(p))\n",
    "            else:\n",
    "                clean_prob.append(float(p))\n",
    "\n",
    "    plt.clf()\n",
    "    kwargs = dict(histtype='stepfilled', alpha=0.75, density=False, bins=20)\n",
    "    plt.hist(clean_prob, color='green', range=(0., 1.), label='clean', **kwargs)\n",
    "    plt.hist(noise_prob, color='red'  , range=(0., 1.), label='noisy', **kwargs)\n",
    "\n",
    "    plt.axvline(x=threshold,          color='black')\n",
    "    plt.axvline(x=origin_prob.mean(), color='gray')\n",
    "    plt.xlabel('JSD Values')\n",
    "    plt.ylabel('count')\n",
    "    plt.title(f'JSD Distribution of N Samples epoch :{epoch}')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{model_save_loc}/{args.dataset}_{args.noise_mode}_{str(args.ratio)}_{epoch}_JSD.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01202563-d2d4-4d4b-b93e-249da26202a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labeled_trainloader, unlabeled_trainloader = loader.run(SR, 'train', prob= JSDs) # Uniform Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d003dd8-0da1-42ba-9bca-d1825975715e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logJSD(epoch, threshold, labeled_trainloader, unlabeled_trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6ffad-7f96-4d42-b7c6-6da20b773154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
